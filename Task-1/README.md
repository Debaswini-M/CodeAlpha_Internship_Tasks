#  Task 1: Disease Prediction from Medical Data



---

## ðŸ“Œ Objective
The goal of this project is to **predict the presence of heart disease** using a medical dataset by applying machine learning classification models.

---

## ðŸ“Š Dataset Description

- **Source:** UCI Machine Learning Repository â€“ Heart Disease Dataset
- **Target Variable:** Presence of heart disease (binary/multiclass)
- **Features Used:**
  - Age, Sex, Chest Pain Type (cp), Resting Blood Pressure (trestbps)
  - Cholesterol, Fasting Blood Sugar (fbs), Rest ECG (restecg)
  - Max Heart Rate Achieved (thalch), Exercise Induced Angina (exang)
  - ST depression (oldpeak), Slope, Number of Vessels (ca)
  - Thalassemia (thal)

---

## âš™ï¸ Tools & Libraries

- **Programming Language:** Python
- **Libraries Used:**
  - `pandas`, `numpy` â€“ data handling
  - `matplotlib` â€“ data visualization
  - `scikit-learn` â€“ ML modeling and evaluation
  - `xgboost` â€“ advanced boosting model

---

## ðŸ§  ML Models Used

| Model                  | Notes                                     |
|-----------------------|-------------------------------------------|
| Logistic Regression    | Baseline classifier with balanced class weights |
| Support Vector Machine | Non-linear classifier with probability outputs |
| Random Forest          | Ensemble decision trees with balanced weights |
| XGBoost                | Gradient boosting classifier with max depth control |

---

## ðŸ§¼ Preprocessing Steps

1. **Data Cleaning**
   - Removed irrelevant columns: `id`, `dataset`
   - Replaced zero values with `NaN` in medically impossible fields
2. **Imputation**
   - Used **median** for continuous features (`chol`, `trestbps`, etc.)
   - Used **mode** for binary/categorical features (`fbs`, `exang`)
3. **Encoding**
   - Applied **Ordinal Encoding** to binary columns (`sex`, `fbs`, `exang`)
   - (Optional) One-Hot Encoding available for future extension
4. **Feature Scaling**
   - StandardScaler applied to all numerical features
5. **Train-Test Split**
   - 80.1/19.9 stratified split to preserve target distribution

---

## ðŸ“ˆ Evaluation Metrics

Each model was evaluated using:

- **Accuracy**
- **ROC AUC Score (macro, one-vs-rest)**
- **Classification Report** (Precision, Recall, F1-score)

---

## ðŸ“Š Model Comparison (Sample Result)

| Model               | Accuracy | ROC AUC |
|--------------------|----------|---------|
| Logistic Regression | 0.80     | 0.93    |
| Random Forest       | 1.00     | 1.00    |
| SVM                 | 0.90     | 0.79    |
| XGBoost             | 1.00     | 1.00    |

>  Note: Actual values may vary per execution due to random state and data splits.

---

## ðŸ“‰ Visualization

Bar plot comparison between **Accuracy** and **ROC AUC** for all models was included using `matplotlib`, helping visualize performance across classifiers.

---

## Author
**Debaswini**

---

